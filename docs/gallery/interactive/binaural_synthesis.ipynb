{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binaural synthesis\n",
    "\n",
    "First, we will briefly talk about the basics of binaural synthesis.\n",
    "\n",
    "Humans can localize sound events about their perceived distance and their angular position in space.\n",
    "Sound waves are altered due to reflections, diffraction, and resonances caused by the presence of a human body, head, shoulders, torso, and the fine structure of the ear formed by pinna, cavum conchae, etc.\n",
    "All these effects, which in its assembly are evaluated by the human brain to localize a source or to get other spatial information, are integrated into binaural signals.\n",
    "If the binaural signal is reproduced perfectly at the eardrums (the human microphones), there is no chance to distinguish the virtual source or environment from the real sound field.\n",
    "With binaural synthesis, a filtering approach with special filters, an acoustic sound source represented by a mono-signal can be virtually placed at arbitrary space positions.\n",
    "\n",
    "## HRTF dataset\n",
    "\n",
    "A valid way to describe all linear sound transformations caused by torso, head, and pinna is using so-called “head-related transfer functions” (HRTFs).\n",
    "For each direction of sound incidence from a sound source to a human receiver, two transfer functions exist (one for the left and one for the right ear), combined into a two-channel HRTF in the frequency domain.\n",
    "Combining all directions into a single database is commonly called an HRTF dataset.\n",
    "The time domain version of HRTFs are also known as \"head-related impulse responses\" (HRIRs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# import the required packages\n",
    "import pyfar as pf\n",
    "import sofar as sf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "files = pf.signals.files._load_files('head_related_impulse_responses')\n",
    "hrir_file = os.path.join(pf.signals.files.file_dir, files[0])\n",
    "\n",
    "# load a SOFA file containing the HRIR dataset\n",
    "hrirs, sources, _ = pf.io.read_sofa(hrir_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are loading the included HRIR dataset from the FABIAN dummy head by [Brinkmann _et al._](https://depositonce.tu-berlin.de/items/3b423df7-a764-4ce1-9065-4e6034bba759).\n",
    "`pyfar` includes a [method to load specific HRIRs from the dataset](https://pyfar.readthedocs.io/en/stable/modules/pyfar.signals.files.html#pyfar.signals.files.head_related_impulse_responses) but the example shown here is the general approach for loading a SOFA file.\n",
    "\n",
    "First, we will plot all possible source locations that are contained in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the included dataset only contains a limited number of source positions - namely, the horizontal plane and the median plane.\n",
    "In practice, an HRIR dataset usually contains more source positions covering the whole sphere around the listener.\n",
    "\n",
    "Using the `pyfar` coordinates, <!-- LINK TODO --> a specific direction can be selected from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the direction of the desired sound source; here, we choose the right direction\n",
    "elevation = 0\n",
    "azimuth = -90\n",
    "\n",
    "# convert to radians\n",
    "elevation = elevation * np.pi / 180\n",
    "azimuth = azimuth * np.pi / 180\n",
    "\n",
    "desired_direction = pf.Coordinates.from_spherical_elevation(\n",
    "    azimuth, elevation, 2\n",
    ")\n",
    "\n",
    "index, _ = sources.find_nearest(desired_direction)\n",
    "\n",
    "sources.show(index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the plot, the selected direction is marked with a red dot."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
